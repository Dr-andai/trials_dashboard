{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up directory paths\n",
    "RAW_DATA_DIR = '../data/raw/'\n",
    "PROCESSED_DATA_DIR = '../data/processed/'\n",
    "\n",
    "aact_data_path = 'aact_folder/aact_data'\n",
    "author_publications = 'scholarly/authors_published_03.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aact_df = pd.read_csv(os.path.join(RAW_DATA_DIR, aact_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive investigator details\n",
    "investigator = aact_df.groupby('investigator')[['nct_id','sponsor_name']].first()\n",
    "investigator_df = investigator.reset_index()\n",
    "\n",
    "investigator_df = investigator_df.sort_values(by='nct_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEAN INVESTIGATOR COLUMN\n",
    "\n",
    "# convert to lower case\n",
    "investigator_df['investigator'] = investigator_df['investigator'].str.lower()\n",
    "\n",
    "# remove periods\n",
    "investigator_df['investigator'] = investigator_df['investigator'].str.replace(r'[.,]', '', regex=True)\n",
    "\n",
    "# reomve titles\n",
    "title_strings = ['md', 'phd', 'mmed', 'dph', 'md','prof', 'dnb','msc','mph','mbchb','mbbs','frcp']\n",
    "regex_pattern = '|'.join(title_strings)\n",
    "\n",
    "investigator_df['investigator']  = investigator_df['investigator'] .str.replace(regex_pattern, '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Processed Data\n",
    "\n",
    "def save_processed_data(data, data_path):\n",
    "    #create a dir if it does not exist\n",
    "    path = os.path.join(PROCESSED_DATA_DIR, data_path.split('/')[0])\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    saved_path = os.path.join(PROCESSED_DATA_DIR, f'{data_path}.csv')\n",
    "    data.to_csv(saved_path, index=False)\n",
    "    \n",
    "    # Get the absolute path\n",
    "    abs_path = os.path.abspath(saved_path)\n",
    "\n",
    "    print(\"Saved to ✅:\", abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'investigator_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m save_processed_data(\u001b[43minvestigator_df\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthors/author\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'investigator_df' is not defined"
     ]
    }
   ],
   "source": [
    "save_processed_data(investigator_df, 'authors/author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scholarly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## testing data extraction\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mscholarly\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscholarly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scholarly\n\u001b[0;32m      5\u001b[0m search \u001b[38;5;241m=\u001b[39m scholarly\u001b[38;5;241m.\u001b[39msearch_author(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirdausi qadri\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scholarly' is not defined"
     ]
    }
   ],
   "source": [
    "## testing data extraction\n",
    "scholarly\n",
    "from scholarly import scholarly\n",
    "\n",
    "search = scholarly.search_author('firdausi qadri')\n",
    "author = next(search)\n",
    "\n",
    "# print(author)\n",
    "\n",
    "author = scholarly.fill(author)\n",
    "for publication in author['publications']:\n",
    "    print(publication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Author, Publication and Journal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author publications data from RAW folder\n",
    "author_publications_df = pd.read_csv(os.path.join(RAW_DATA_DIR, author_publications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'title': 'Guillain-Barré syndrome related to ...\n",
       "1    {'title': 'The chemotherapy-induced peripheral...\n",
       "2    {'title': 'Chemotherapy-induced peripheral neu...\n",
       "3    {'title': 'Clinical pattern and associations o...\n",
       "4    {'title': 'Understanding the quality of life (...\n",
       "Name: bib, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications = author_publications_df.loc[:,['investigator','bib','num_citations']]\n",
    "publications['bib'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from the json format in bib column\n",
    "import ast\n",
    "publications['bib'] = publications['bib'] .apply(ast.literal_eval)\n",
    "\n",
    "info_df = pd.json_normalize(publications['bib'])\n",
    "\n",
    "publication_details = pd.concat([publications.drop(columns='bib'),info_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the following tables with the following columns:\n",
    "\n",
    "- Authors  \n",
    "*id*  \n",
    "*name*  \n",
    "*author_title*  \n",
    "*instituition*\n",
    "\n",
    "- Journal  \n",
    "*journal_name*  \n",
    "*country*  \n",
    "*year*  \n",
    "*impactor_factor*\n",
    "\n",
    "- Publication  \n",
    "*publication_title*  \n",
    "*date*  \n",
    "*citations*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paola alberti', 'kishal lukhna']\n"
     ]
    }
   ],
   "source": [
    "## extract unique authors from the investigator column\n",
    "author_list = publication_details['investigator'].unique().tolist()\n",
    "print(author_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create authors data frame\n",
    "Authors = pd.DataFrame({\n",
    "    'name':author_list,\n",
    "    'author_title': \"nil\",\n",
    "    'institution': \"nil\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create journals data frame\n",
    "## extract journal \n",
    "Journals = publication_details.loc[:,['investigator','citation']]\n",
    "Journals = Journals.assign(country = None, year = None, impact_factor = None)\n",
    "\n",
    "# rename journal names\n",
    "Journals.rename(columns={\n",
    "    'investigator':'author',\n",
    "    'citations':'journal_name'}, \n",
    "    inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_3572\\1245384555.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  Journals['citation'].replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# remove everything remain with letters. (will have to review this bit though)\n",
    "Journals['citation'] = Journals['citation'].str.replace(r'[0-9]', '', regex=True)\n",
    "Journals['citation'] = Journals['citation'].str.replace(r'[.,]', '', regex=True)\n",
    "Journals['citation'] = Journals['citation'].str.replace(r'[-]', '', regex=True)\n",
    "Journals['citation'] = Journals['citation'].str.replace(r'[:,\\(\\)]', '', regex=True)\n",
    "Journals['citation'].replace(r'^\\s*$', np.nan, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the Journals table\n",
    "Journals.fillna({'citation':'Data_not_available'}, inplace=True)\n",
    "Journals.fillna({'impact_factor':0}, inplace=True)\n",
    "Journals.fillna({'year':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Journals['impact_factor'] = Journals['impact_factor'].astype('int64')\n",
    "Journals['year'] = Journals['year'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create publication data frame\n",
    "Publications = publication_details.loc[:,['investigator','title','pub_year','num_citations']]\n",
    "\n",
    "# rename Publication names\n",
    "Publications.rename(columns={\n",
    "    'investigator':'author',\n",
    "    'title' : 'publication_title',\n",
    "    'pub_year':'year',\n",
    "    'num_citations':'citations'}, \n",
    "    inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove periods\n",
    "Publications['publication_title'] = Publications['publication_title'].str.replace(r'[0-9]', '', regex=True)\n",
    "Publications['publication_title'] = Publications['publication_title'].str.replace(r'[.,]', '', regex=True)\n",
    "Publications['publication_title'] = Publications['publication_title'].str.replace(r'[-]', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def truncate_to_five_words(text):\n",
    "#     words = text.split()\n",
    "#     return ' '.join(words[:5])\n",
    "\n",
    "# # Apply this function to the desired column\n",
    "# # Replace 'your_column' with the name of the column you want to process\n",
    "# Publications['publication_title'] = Publications['publication_title'].apply(truncate_to_five_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author               object\n",
       "publication_title    object\n",
       "year                  int64\n",
       "citations             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Publications.fillna({'year': 0 }, inplace=True)\n",
    "Publications['year'] = Publications['year'].astype('int64')\n",
    "\n",
    "Publications['year'] = Publications['year'].astype('int64')\n",
    "Publications.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ✅: c:\\Users\\Hp\\OneDrive\\OLDFILES\\Documents\\PROJECTS\\trials_dashboard\\data\\processed\\model_data\\authors.csv\n",
      "Saved to ✅: c:\\Users\\Hp\\OneDrive\\OLDFILES\\Documents\\PROJECTS\\trials_dashboard\\data\\processed\\model_data\\publications.csv\n",
      "Saved to ✅: c:\\Users\\Hp\\OneDrive\\OLDFILES\\Documents\\PROJECTS\\trials_dashboard\\data\\processed\\model_data\\journals.csv\n"
     ]
    }
   ],
   "source": [
    "## Save to Processed folder\n",
    "save_processed_data(Authors, 'model_data/authors')\n",
    "save_processed_data(Publications, 'model_data/publications')\n",
    "save_processed_data(Journals, 'model_data/journals')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
